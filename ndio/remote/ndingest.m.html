<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>ndio.remote.ndingest API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>


  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">
    <li class="set"><h3><a href="#header-variables">Module variables</a></h3>
      
  <ul>
    <li class="mono"><a href="#ndio.remote.ndingest.SCHEMA_BASE">SCHEMA_BASE</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.VERIFY_BY_FOLDER">VERIFY_BY_FOLDER</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.VERIFY_BY_SLICE">VERIFY_BY_SLICE</a></li>
  </ul>

    </li>


    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#ndio.remote.ndingest.NDIngest">NDIngest</a></span>
        
          
  <ul>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.__init__">__init__</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.add_channel">add_channel</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.add_dataset">add_dataset</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.add_metadata">add_metadata</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.add_project">add_project</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.channel_dict">channel_dict</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.dataset_dict">dataset_dict</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.identify_imagesize">identify_imagesize</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.nd_json">nd_json</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.nd_json_list">nd_json_list</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.output_json">output_json</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.post_data">post_data</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.project_dict">project_dict</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.put_data">put_data</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.verify_json">verify_json</a></li>
    <li class="mono"><a href="#ndio.remote.ndingest.NDIngest.verify_path">verify_path</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">ndio.remote.ndingest</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest" class="source">
    <pre><code>from __future__ import absolute_import
import json
import os
import requests
from jsonspec.validators import load
import re
import shutil
from .neurodata import neurodata as nd
import ndio.convert.tiff as ndtiff
import ndio.convert.png as ndpng
import numpy as np

VERIFY_BY_FOLDER = 'Folder'
VERIFY_BY_SLICE = 'Slice'

# schema base
SCHEMA_BASE = "https://" + "/".join([
    "raw.githubusercontent.com",
    "neurodata/ndstore",
    "master",
    "/docs/sphinx"
])


class NDIngest:
    """
    A remote to automate the ingest of large volumetric data into ndstore.
    """

    def __init__(self, site_host=None):
        """
        Arguments:
            site_host(str): The site host to post the data to, by default
                http://openconnectome.me.

        Returns:
            None
        """
        self.channels = {}
        self.dataset = []
        self.project = []
        self.metadata = ''
        if site_host is not None:
            self.oo = nd(site_host)
        else:
            self.oo = nd()

        rd = requests.get('{}/dataset_schema.json'.format(SCHEMA_BASE))
        if (rd.status_code < 300):
            self.DATASET_SCHEMA = load(eval(str(rd.text)))
        else:
            raise OSError("Dataset schema not available")

        rc = requests.get('{}/channel_schema.json'.format(SCHEMA_BASE))
        if (rc.status_code < 300):
            self.CHANNEL_SCHEMA = load(eval(str(rc.text)))
        else:
            raise OSError("Channel schema not available")

        rp = requests.get('{}/project_schema.json'.format(SCHEMA_BASE))
        if (rp.status_code < 300):
            self.PROJECT_SCHEMA = load(eval(str(rp.text)))
        else:
            raise Value("Project schema not available")

    def add_channel(self, channel_name, datatype, channel_type,
                    data_url, file_format, file_type, exceptions=None,
                    resolution=None, windowrange=None, readonly=None):
        """
        Arguments:
            channel_name (str): Channel Name is the specific name of a
                specific series of data. Standard naming convention is to do
                ImageTypeIterationNumber or NameSubProjectName.
            datatype (str): The data type is the storage method of data in
                the channel. It can be uint8, uint16, uint32, uint64, or
                float32.
            channel_type (str): The channel type is the kind of data being
                stored in the channel. It can be image, annotation, or
                timeseries.
            data_url (str): This url points to the root directory of the
                files. Dropbox (or any data requiring authentication to
                download such as private s3) is not an acceptable HTTP
                Server. See additional instructions in documentation online
                to format s3 properly so it is http accessible.
            file_format (str): File format refers to the overarching kind
                of data, as in slices (normal image data) or catmaid
                (tile-based).
            file_type (str): File type refers to the specific type of file
                that the data is stored in, as in, tiff, png, or tif.
            exceptions (int): Exceptions is an option to enable the
                possibility for annotations to contradict each other (assign
                different values to the same point). 1 corresponds to True,
                0 corresponds to False.
            resolution (int): Resolution is the starting resolution of the
                data being uploaded to the channel.
            windowrange (int, int): Window range is the maximum and minimum
                pixel values for a particular image. This is used so that the
                image can be displayed in a readable way for viewing through
                RESTful calls
            readonly (int): This option allows the user to control if,
                after the initial data commit, the channel is read-only.
                Generally this is suggested with data that will be publicly
                viewable.

        Returns:
            None
        """
        self.channels[channel_name] = [
            channel_name.strip().replace(" ", ""), datatype,
            channel_type.lower(), data_url,
            file_format, file_type, exceptions, resolution,
            windowrange, readonly
        ]

    def add_project(self, project_name, token_name=None, public=None):
        """
        Arguments:
            project_name (str): Project name is the specific project within
                a dataset's name. If there is only one project associated
                with a dataset then standard convention is to name the
                project the same as its associated dataset.
            token_name (str): The token name is the default token. If you
                do not wish to specify one, a default one will be created for
                you with the same name as the project name. However, if the
                project is private you must specify a token.
            public (int): This option allows users to specify if they want
                the project/channels to be publicly viewable/search-able.
                (1, 0) = (TRUE, FALSE)

        Returns:
            None
        """
        self.project = (project_name.strip().replace(" ", ""),
                        token_name.strip().replace(" ", ""), public)

    def add_dataset(self, dataset_name, imagesize, voxelres, offset=None,
                    timerange=None, scalinglevels=None, scaling=None):
        """
        Add a new dataset to the ingest.

        Arguments:
            dataset_name (str): Dataset Name is the overarching name of the
                research effort. Standard naming convention is to do
                LabNamePublicationYear or LeadResearcherCurrentYear.
            imagesize (int, int, int): Image size is the pixel count
                dimensions of the data. For example is the data is stored
                as a series of 100 slices each 2100x2000 pixel TIFF images,
                the X,Y,Z dimensions are (2100, 2000, 100).
            voxelres (float, float, float): Voxel Resolution is the number
                of voxels per unit pixel. We store X,Y,Z voxel resolution
                separately.
            offset (int, int, int): If your data is not well aligned and
                there is "excess" image data you do not wish to examine, but
                are present in your images, offset is how you specify where
                your actual image starts. Offset is provided a pixel
                coordinate offset from origin which specifies the "actual"
                origin of the image. The offset is for X,Y,Z dimensions.
            timerange (int, int): Time Range is a parameter to support
                storage of Time Series data, so the value of the tuple is a
                0 to X range of how many images over time were taken. It
                takes 2 inputs timeStepStart and timeStepStop.
            scalinglevels (int): Scaling levels is the number of levels the
                data is scalable to (how many zoom levels are present in the
                data). The highest resolution of the data is at scaling level
                0, and for each level up the data is down sampled by 2x2
                (per slice). To learn more about the sampling service used,
                visit the the propagation service page.
            scaling (int): Scaling is the scaling method of the data being
                stored. 0 corresponds to a Z-slice orientation (as in a
                collection of tiff images in which each tiff is a slice on
                the z plane) where data will be scaled only on the xy plane,
                not the z plane. 1 corresponds to an isotropic orientation
                (in which each tiff is a slice on the y plane) where data
                is scaled along all axis.

        Returns:
            None
        """
        self.dataset = (dataset_name.strip().replace(" ", ""), imagesize,
                        voxelres, offset, timerange, scalinglevels, scaling)

    def add_metadata(self, metadata=""):
        """
        Arguments:
            metadata(str): Any metadata as appropriate from the LIMS schema

        Returns:
            None
        """
        self.metadata = metadata

    def nd_json(self, dataset, project, channel_list, metadata):
        """
        Genarate ND json object.
        """
        nd_dict = {}
        nd_dict['dataset'] = self.dataset_dict(*dataset)
        nd_dict['project'] = self.project_dict(*project)
        nd_dict['metadata'] = metadata
        nd_dict['channels'] = {}
        for channel_name, value in channel_list.items():
            nd_dict['channels'][channel_name] = self.channel_dict(*value)

        return json.dumps(nd_dict, sort_keys=True, indent=4)

    def nd_json_list(self, dataset, project, channel_list, metadata):
        """
        Genarate ND json object.
        """
        nd_dict = {}
        nd_dict['dataset'] = self.dataset_dict(*dataset)
        nd_dict['project'] = self.project_dict(*project)
        nd_dict['metadata'] = metadata
        nd_dict['channels'] = {}
        for channel_name, value in channel_list.items():
            nd_dict['channels'].append(self.channel_dict(*value))

        return json.dumps(nd_dict, sort_keys=True, indent=4)

    def dataset_dict(
        self, dataset_name, imagesize, voxelres,
            offset, timerange, scalinglevels, scaling):
        """Generate the dataset dictionary"""
        dataset_dict = {}
        dataset_dict['dataset_name'] = dataset_name
        dataset_dict['imagesize'] = imagesize
        dataset_dict['voxelres'] = voxelres
        if offset is not None:
            dataset_dict['offset'] = offset
        if timerange is not None:
            dataset_dict['timerange'] = timerange
        if scalinglevels is not None:
            dataset_dict['scalinglevels'] = scalinglevels
        if scaling is not None:
            dataset_dict['scaling'] = scaling
        return dataset_dict

    def channel_dict(self, channel_name, datatype, channel_type, data_url,
                     file_format, file_type, exceptions, resolution,
                     windowrange, readonly):
        """
        Generate the project dictionary.
        """
        channel_dict = {}
        channel_dict['channel_name'] = channel_name
        channel_dict['datatype'] = datatype
        channel_dict['channel_type'] = channel_type
        if exceptions is not None:
            channel_dict['exceptions'] = exceptions
        if resolution is not None:
            channel_dict['resolution'] = resolution
        if windowrange is not None:
            channel_dict['windowrange'] = windowrange
        if readonly is not None:
            channel_dict['readonly'] = readonly
        channel_dict['data_url'] = data_url
        channel_dict['file_format'] = file_format
        channel_dict['file_type'] = file_type
        return channel_dict

    def project_dict(self, project_name, token_name, public):
        """
        Genarate the project dictionary.
        """
        project_dict = {}
        project_dict['project_name'] = project_name
        if token_name is not None:
            if token_name == '':
                project_dict['token_name'] = project_name
            else:
                project_dict['token_name'] = token_name
        else:
            project_dict['token_name'] = project_name

        if public is not None:
            project_dict['public'] = public
        return project_dict

    def identify_imagesize(self, image_type, image_path='/tmp/img.'):
        """
        Identify the image size using the data location and other parameters
        """
        dims = ()
        try:
            if (image_type.lower() == 'png'):
                dims = np.shape(ndpng.load('{}{}'.format(
                    image_path, image_type
                )))
            elif (image_type.lower() == 'tif' or image_type.lower() == 'tiff'):
                dims = np.shape(ndtiff.load('{}{}'.format(
                    image_path, image_type
                )))

            else:
                raise ValueError("Unsupported image type.")
        except:
            raise OSError('The file was not accessible at {}{}'.format(
                image_path,
                image_type
            ))
        return dims[::-1]

    def verify_path(self, data, verifytype):
        """
        Verify the path supplied.
        """
        # Insert try and catch blocks
        try:
            token_name = data["project"]["token_name"]
        except:
            token_name = data["project"]["project_name"]

        channel_names = list(data["channels"].copy().keys())
        imgsz = data['dataset']['imagesize']

        for i in range(0, len(channel_names)):
            channel_type = data["channels"][
                channel_names[i]]["channel_type"]
            path = data["channels"][channel_names[i]]["data_url"]
            aws_pattern = re.compile("^(http:\/\/)(.+)(\.s3\.amazonaws\.com)")
            file_type = data["channels"][channel_names[i]]["file_type"]
            if "offset" in data["dataset"]:
                offset = data["dataset"]["offset"][0]
            else:
                offset = 0

            if (aws_pattern.match(path)):
                verifytype = VERIFY_BY_SLICE

            if (channel_type == "timeseries"):
                timerange = data["dataset"]["timerange"]
                try:
                    assert(timerange[0] != timerange[1])
                except AssertionError:
                    raise ValueError('Timeseries values are the same, did you\
specify the time steps?')
                for j in range(timerange[0], timerange[1] + 1):
                    # Test for tifs or such? Currently test for just not
                    # empty
                    if (verifytype == VERIFY_BY_FOLDER):
                        work_path = "{}/{}/{}/time{}/".format(
                            path, token_name, channel_names[i], ("%04d" % j))
                    elif (verifytype == VERIFY_BY_SLICE):
                        work_path = "{}/{}/{}/time{}/{}.{}".format(
                            path, token_name, channel_names[i], ("%04d" % j),
                            ("%04d" % offset), file_type)
                    else:
                        raise TypeError('Incorrect verify method')
                    # Check for accessibility
                    try:
                        if (verifytype == VERIFY_BY_FOLDER):
                            resp = requests.head(work_path)
                            assert(resp.status_code == 200)
                        elif (verifytype == VERIFY_BY_SLICE):
                            resp = requests.get(work_path, stream=True)
                            with open('/tmp/img.{}'.format(file_type),
                                      'wb') as out_file:
                                shutil.copyfileobj(resp.raw, out_file)
                            out_file.close()
                            assert(resp.status_code == 200)
                            resp.close()
                    except AssertionError:
                        raise OSError('Files are not http accessible: \
                            Error: {}, Path: {}'.format(resp.status_code,
                                                        work_path))
                    # Attempt to Verify imagesize here

                    try:
                        if (verifytype == VERIFY_BY_SLICE):
                            assert(list(self.identify_imagesize(file_type)) ==
                                   imgsz[0:2])
                    except:
                        raise ValueError('File image size does not match\
provided image size.')

            else:
                # Test for tifs or such? Currently test for just not empty
                if (verifytype == VERIFY_BY_FOLDER):
                    work_path = "{}/{}/{}/".format(
                        path, token_name, channel_names[i])
                elif (verifytype == VERIFY_BY_SLICE):
                    work_path = "{}/{}/{}/{}.{}".format(
                        path, token_name, channel_names[i],
                        ("%04d" % offset), file_type)
                else:
                    raise TypeError('Incorrect verify method')
                # Check for accessibility
                if (verifytype == VERIFY_BY_FOLDER):
                    resp = requests.head(work_path)
                elif (verifytype == VERIFY_BY_SLICE):
                    resp = requests.get(work_path, stream=True)
                    with open('/tmp/img.{}'.format(file_type),
                              'wb') as out_file:
                        shutil.copyfileobj(resp.raw, out_file)
                    out_file.close()
                    resp.close()
                if (resp.status_code >= 300):
                    raise OSError('Files are not http accessible: \
                            Error: {}, Path: {}'.format(resp.status_code,
                                                        work_path))
                # Attempt to Verify imagesize here

                try:
                    if (verifytype == VERIFY_BY_SLICE):
                        assert(list(self.identify_imagesize(file_type)) ==
                               imgsz[0:2])
                except:
                    raise ValueError('File image size does not match\
provided image size.')

            # By Here the path should have been verified

    def verify_json(self, data):
        """
        Verify the JSON against the spec.
        """
        names = []
        # Channels
        channel_names = list(data["channels"].copy().keys())
        for i in range(0, len(channel_names)):
            channel_object = data["channels"][channel_names[i]]
            try:
                self.CHANNEL_SCHEMA.validate(channel_object)
            except:
                raise ValueError("channel " + channel_object["channel_name"])
            names.append(channel_object["channel_name"])
        # Dataset"
        dataset_object = data["dataset"]
        try:
            self.DATASET_SCHEMA.validate(dataset_object)
        except:
            raise ValueError("Error in dataset parameters")
        names.append(dataset_object["dataset_name"])

        # Project
        project_object = data["project"]
        try:
            self.PROJECT_SCHEMA.validate(project_object)
        except:
            raise ValueError("Error in project parameters")
        names.append(project_object["project_name"])

        # Check if names contain bad chars. Underscore is allowed
        spec_chars = re.compile(".*[$&+,:;=?@#|'<>.^*()%!-].*")

        for i in names:
            if(spec_chars.match(i)):
                raise ValueError("Error. No special characters allowed \
including: $&+,:;=?@#|'<>.^*()%!-].* in dataset, project, channel or token \
names")

    def put_data(self, data):
        """
        Try to post data to the server.
        """
        URLPath = self.oo.url("autoIngest/")
        try:
            response = requests.post(URLPath, data=json.dumps(data))
            assert(response.status_code == 200)
            print("From ndio: {}".format(response.content))
        except:
            raise OSError("Error in posting JSON file {}\
".format(response.status_code))

    def post_data(self,
                  file_name=None, legacy=False,
                  verifytype=VERIFY_BY_SLICE):
        """
        Arguments:
            file_name (str): The file name of the json file to post (optional).
                If this is left unspecified it is assumed the data is in the
                AutoIngest object.
            dev (bool): If pushing to a microns dev branch server set this
                to True, if not leave False.
            verifytype (enum): Set http verification type, by checking the
                first slice is accessible or by checking channel folder.
                NOTE: If verification occurs by folder there is NO image size
                or type verification. Enum: [Folder, Slice]

        Returns:
            None
        """
        if (file_name is None):
            complete_example = (
                self.dataset, self.project, self.channels, self.metadata)
            data = json.loads(self.nd_json(*complete_example))

        else:
            try:
                with open(file_name) as data_file:
                    data = json.load(data_file)
            except:
                raise OSError("Error opening file")

        self.verify_path(data, verifytype)
        self.verify_json(data)
        self.put_data(data)

    def output_json(self, file_name='/tmp/ND.json'):
        """
        Arguments:
            file_name(str : '/tmp/ND.json'): The file name to store the json to

        Returns:
            None
        """
        complete_example = (
            self.dataset, self.project, self.channels, self.metadata)
        data = json.loads(self.nd_json(*complete_example))

        self.verify_json(data)
        self.verify_path(data, VERIFY_BY_SLICE)

        f = open(file_name, 'w')
        f.write(str(data))
        f.close()
</code></pre>
  </div>

  </header>

  <section id="section-items">
    <h2 class="section-title" id="header-variables">Module variables</h2>
      <div class="item">
      <p id="ndio.remote.ndingest.SCHEMA_BASE" class="name">var <span class="ident">SCHEMA_BASE</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="ndio.remote.ndingest.VERIFY_BY_FOLDER" class="name">var <span class="ident">VERIFY_BY_FOLDER</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="ndio.remote.ndingest.VERIFY_BY_SLICE" class="name">var <span class="ident">VERIFY_BY_SLICE</span></p>
      
  
  <div class="source_cont">
</div>

      </div>


    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="ndio.remote.ndingest.NDIngest" class="name">class <span class="ident">NDIngest</span></p>
      
  
    <div class="desc"><p>A remote to automate the ingest of large volumetric data into ndstore.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest" class="source">
    <pre><code>class NDIngest:
    """
    A remote to automate the ingest of large volumetric data into ndstore.
    """

    def __init__(self, site_host=None):
        """
        Arguments:
            site_host(str): The site host to post the data to, by default
                http://openconnectome.me.

        Returns:
            None
        """
        self.channels = {}
        self.dataset = []
        self.project = []
        self.metadata = ''
        if site_host is not None:
            self.oo = nd(site_host)
        else:
            self.oo = nd()

        rd = requests.get('{}/dataset_schema.json'.format(SCHEMA_BASE))
        if (rd.status_code < 300):
            self.DATASET_SCHEMA = load(eval(str(rd.text)))
        else:
            raise OSError("Dataset schema not available")

        rc = requests.get('{}/channel_schema.json'.format(SCHEMA_BASE))
        if (rc.status_code < 300):
            self.CHANNEL_SCHEMA = load(eval(str(rc.text)))
        else:
            raise OSError("Channel schema not available")

        rp = requests.get('{}/project_schema.json'.format(SCHEMA_BASE))
        if (rp.status_code < 300):
            self.PROJECT_SCHEMA = load(eval(str(rp.text)))
        else:
            raise Value("Project schema not available")

    def add_channel(self, channel_name, datatype, channel_type,
                    data_url, file_format, file_type, exceptions=None,
                    resolution=None, windowrange=None, readonly=None):
        """
        Arguments:
            channel_name (str): Channel Name is the specific name of a
                specific series of data. Standard naming convention is to do
                ImageTypeIterationNumber or NameSubProjectName.
            datatype (str): The data type is the storage method of data in
                the channel. It can be uint8, uint16, uint32, uint64, or
                float32.
            channel_type (str): The channel type is the kind of data being
                stored in the channel. It can be image, annotation, or
                timeseries.
            data_url (str): This url points to the root directory of the
                files. Dropbox (or any data requiring authentication to
                download such as private s3) is not an acceptable HTTP
                Server. See additional instructions in documentation online
                to format s3 properly so it is http accessible.
            file_format (str): File format refers to the overarching kind
                of data, as in slices (normal image data) or catmaid
                (tile-based).
            file_type (str): File type refers to the specific type of file
                that the data is stored in, as in, tiff, png, or tif.
            exceptions (int): Exceptions is an option to enable the
                possibility for annotations to contradict each other (assign
                different values to the same point). 1 corresponds to True,
                0 corresponds to False.
            resolution (int): Resolution is the starting resolution of the
                data being uploaded to the channel.
            windowrange (int, int): Window range is the maximum and minimum
                pixel values for a particular image. This is used so that the
                image can be displayed in a readable way for viewing through
                RESTful calls
            readonly (int): This option allows the user to control if,
                after the initial data commit, the channel is read-only.
                Generally this is suggested with data that will be publicly
                viewable.

        Returns:
            None
        """
        self.channels[channel_name] = [
            channel_name.strip().replace(" ", ""), datatype,
            channel_type.lower(), data_url,
            file_format, file_type, exceptions, resolution,
            windowrange, readonly
        ]

    def add_project(self, project_name, token_name=None, public=None):
        """
        Arguments:
            project_name (str): Project name is the specific project within
                a dataset's name. If there is only one project associated
                with a dataset then standard convention is to name the
                project the same as its associated dataset.
            token_name (str): The token name is the default token. If you
                do not wish to specify one, a default one will be created for
                you with the same name as the project name. However, if the
                project is private you must specify a token.
            public (int): This option allows users to specify if they want
                the project/channels to be publicly viewable/search-able.
                (1, 0) = (TRUE, FALSE)

        Returns:
            None
        """
        self.project = (project_name.strip().replace(" ", ""),
                        token_name.strip().replace(" ", ""), public)

    def add_dataset(self, dataset_name, imagesize, voxelres, offset=None,
                    timerange=None, scalinglevels=None, scaling=None):
        """
        Add a new dataset to the ingest.

        Arguments:
            dataset_name (str): Dataset Name is the overarching name of the
                research effort. Standard naming convention is to do
                LabNamePublicationYear or LeadResearcherCurrentYear.
            imagesize (int, int, int): Image size is the pixel count
                dimensions of the data. For example is the data is stored
                as a series of 100 slices each 2100x2000 pixel TIFF images,
                the X,Y,Z dimensions are (2100, 2000, 100).
            voxelres (float, float, float): Voxel Resolution is the number
                of voxels per unit pixel. We store X,Y,Z voxel resolution
                separately.
            offset (int, int, int): If your data is not well aligned and
                there is "excess" image data you do not wish to examine, but
                are present in your images, offset is how you specify where
                your actual image starts. Offset is provided a pixel
                coordinate offset from origin which specifies the "actual"
                origin of the image. The offset is for X,Y,Z dimensions.
            timerange (int, int): Time Range is a parameter to support
                storage of Time Series data, so the value of the tuple is a
                0 to X range of how many images over time were taken. It
                takes 2 inputs timeStepStart and timeStepStop.
            scalinglevels (int): Scaling levels is the number of levels the
                data is scalable to (how many zoom levels are present in the
                data). The highest resolution of the data is at scaling level
                0, and for each level up the data is down sampled by 2x2
                (per slice). To learn more about the sampling service used,
                visit the the propagation service page.
            scaling (int): Scaling is the scaling method of the data being
                stored. 0 corresponds to a Z-slice orientation (as in a
                collection of tiff images in which each tiff is a slice on
                the z plane) where data will be scaled only on the xy plane,
                not the z plane. 1 corresponds to an isotropic orientation
                (in which each tiff is a slice on the y plane) where data
                is scaled along all axis.

        Returns:
            None
        """
        self.dataset = (dataset_name.strip().replace(" ", ""), imagesize,
                        voxelres, offset, timerange, scalinglevels, scaling)

    def add_metadata(self, metadata=""):
        """
        Arguments:
            metadata(str): Any metadata as appropriate from the LIMS schema

        Returns:
            None
        """
        self.metadata = metadata

    def nd_json(self, dataset, project, channel_list, metadata):
        """
        Genarate ND json object.
        """
        nd_dict = {}
        nd_dict['dataset'] = self.dataset_dict(*dataset)
        nd_dict['project'] = self.project_dict(*project)
        nd_dict['metadata'] = metadata
        nd_dict['channels'] = {}
        for channel_name, value in channel_list.items():
            nd_dict['channels'][channel_name] = self.channel_dict(*value)

        return json.dumps(nd_dict, sort_keys=True, indent=4)

    def nd_json_list(self, dataset, project, channel_list, metadata):
        """
        Genarate ND json object.
        """
        nd_dict = {}
        nd_dict['dataset'] = self.dataset_dict(*dataset)
        nd_dict['project'] = self.project_dict(*project)
        nd_dict['metadata'] = metadata
        nd_dict['channels'] = {}
        for channel_name, value in channel_list.items():
            nd_dict['channels'].append(self.channel_dict(*value))

        return json.dumps(nd_dict, sort_keys=True, indent=4)

    def dataset_dict(
        self, dataset_name, imagesize, voxelres,
            offset, timerange, scalinglevels, scaling):
        """Generate the dataset dictionary"""
        dataset_dict = {}
        dataset_dict['dataset_name'] = dataset_name
        dataset_dict['imagesize'] = imagesize
        dataset_dict['voxelres'] = voxelres
        if offset is not None:
            dataset_dict['offset'] = offset
        if timerange is not None:
            dataset_dict['timerange'] = timerange
        if scalinglevels is not None:
            dataset_dict['scalinglevels'] = scalinglevels
        if scaling is not None:
            dataset_dict['scaling'] = scaling
        return dataset_dict

    def channel_dict(self, channel_name, datatype, channel_type, data_url,
                     file_format, file_type, exceptions, resolution,
                     windowrange, readonly):
        """
        Generate the project dictionary.
        """
        channel_dict = {}
        channel_dict['channel_name'] = channel_name
        channel_dict['datatype'] = datatype
        channel_dict['channel_type'] = channel_type
        if exceptions is not None:
            channel_dict['exceptions'] = exceptions
        if resolution is not None:
            channel_dict['resolution'] = resolution
        if windowrange is not None:
            channel_dict['windowrange'] = windowrange
        if readonly is not None:
            channel_dict['readonly'] = readonly
        channel_dict['data_url'] = data_url
        channel_dict['file_format'] = file_format
        channel_dict['file_type'] = file_type
        return channel_dict

    def project_dict(self, project_name, token_name, public):
        """
        Genarate the project dictionary.
        """
        project_dict = {}
        project_dict['project_name'] = project_name
        if token_name is not None:
            if token_name == '':
                project_dict['token_name'] = project_name
            else:
                project_dict['token_name'] = token_name
        else:
            project_dict['token_name'] = project_name

        if public is not None:
            project_dict['public'] = public
        return project_dict

    def identify_imagesize(self, image_type, image_path='/tmp/img.'):
        """
        Identify the image size using the data location and other parameters
        """
        dims = ()
        try:
            if (image_type.lower() == 'png'):
                dims = np.shape(ndpng.load('{}{}'.format(
                    image_path, image_type
                )))
            elif (image_type.lower() == 'tif' or image_type.lower() == 'tiff'):
                dims = np.shape(ndtiff.load('{}{}'.format(
                    image_path, image_type
                )))

            else:
                raise ValueError("Unsupported image type.")
        except:
            raise OSError('The file was not accessible at {}{}'.format(
                image_path,
                image_type
            ))
        return dims[::-1]

    def verify_path(self, data, verifytype):
        """
        Verify the path supplied.
        """
        # Insert try and catch blocks
        try:
            token_name = data["project"]["token_name"]
        except:
            token_name = data["project"]["project_name"]

        channel_names = list(data["channels"].copy().keys())
        imgsz = data['dataset']['imagesize']

        for i in range(0, len(channel_names)):
            channel_type = data["channels"][
                channel_names[i]]["channel_type"]
            path = data["channels"][channel_names[i]]["data_url"]
            aws_pattern = re.compile("^(http:\/\/)(.+)(\.s3\.amazonaws\.com)")
            file_type = data["channels"][channel_names[i]]["file_type"]
            if "offset" in data["dataset"]:
                offset = data["dataset"]["offset"][0]
            else:
                offset = 0

            if (aws_pattern.match(path)):
                verifytype = VERIFY_BY_SLICE

            if (channel_type == "timeseries"):
                timerange = data["dataset"]["timerange"]
                try:
                    assert(timerange[0] != timerange[1])
                except AssertionError:
                    raise ValueError('Timeseries values are the same, did you\
specify the time steps?')
                for j in range(timerange[0], timerange[1] + 1):
                    # Test for tifs or such? Currently test for just not
                    # empty
                    if (verifytype == VERIFY_BY_FOLDER):
                        work_path = "{}/{}/{}/time{}/".format(
                            path, token_name, channel_names[i], ("%04d" % j))
                    elif (verifytype == VERIFY_BY_SLICE):
                        work_path = "{}/{}/{}/time{}/{}.{}".format(
                            path, token_name, channel_names[i], ("%04d" % j),
                            ("%04d" % offset), file_type)
                    else:
                        raise TypeError('Incorrect verify method')
                    # Check for accessibility
                    try:
                        if (verifytype == VERIFY_BY_FOLDER):
                            resp = requests.head(work_path)
                            assert(resp.status_code == 200)
                        elif (verifytype == VERIFY_BY_SLICE):
                            resp = requests.get(work_path, stream=True)
                            with open('/tmp/img.{}'.format(file_type),
                                      'wb') as out_file:
                                shutil.copyfileobj(resp.raw, out_file)
                            out_file.close()
                            assert(resp.status_code == 200)
                            resp.close()
                    except AssertionError:
                        raise OSError('Files are not http accessible: \
                            Error: {}, Path: {}'.format(resp.status_code,
                                                        work_path))
                    # Attempt to Verify imagesize here

                    try:
                        if (verifytype == VERIFY_BY_SLICE):
                            assert(list(self.identify_imagesize(file_type)) ==
                                   imgsz[0:2])
                    except:
                        raise ValueError('File image size does not match\
provided image size.')

            else:
                # Test for tifs or such? Currently test for just not empty
                if (verifytype == VERIFY_BY_FOLDER):
                    work_path = "{}/{}/{}/".format(
                        path, token_name, channel_names[i])
                elif (verifytype == VERIFY_BY_SLICE):
                    work_path = "{}/{}/{}/{}.{}".format(
                        path, token_name, channel_names[i],
                        ("%04d" % offset), file_type)
                else:
                    raise TypeError('Incorrect verify method')
                # Check for accessibility
                if (verifytype == VERIFY_BY_FOLDER):
                    resp = requests.head(work_path)
                elif (verifytype == VERIFY_BY_SLICE):
                    resp = requests.get(work_path, stream=True)
                    with open('/tmp/img.{}'.format(file_type),
                              'wb') as out_file:
                        shutil.copyfileobj(resp.raw, out_file)
                    out_file.close()
                    resp.close()
                if (resp.status_code >= 300):
                    raise OSError('Files are not http accessible: \
                            Error: {}, Path: {}'.format(resp.status_code,
                                                        work_path))
                # Attempt to Verify imagesize here

                try:
                    if (verifytype == VERIFY_BY_SLICE):
                        assert(list(self.identify_imagesize(file_type)) ==
                               imgsz[0:2])
                except:
                    raise ValueError('File image size does not match\
provided image size.')

            # By Here the path should have been verified

    def verify_json(self, data):
        """
        Verify the JSON against the spec.
        """
        names = []
        # Channels
        channel_names = list(data["channels"].copy().keys())
        for i in range(0, len(channel_names)):
            channel_object = data["channels"][channel_names[i]]
            try:
                self.CHANNEL_SCHEMA.validate(channel_object)
            except:
                raise ValueError("channel " + channel_object["channel_name"])
            names.append(channel_object["channel_name"])
        # Dataset"
        dataset_object = data["dataset"]
        try:
            self.DATASET_SCHEMA.validate(dataset_object)
        except:
            raise ValueError("Error in dataset parameters")
        names.append(dataset_object["dataset_name"])

        # Project
        project_object = data["project"]
        try:
            self.PROJECT_SCHEMA.validate(project_object)
        except:
            raise ValueError("Error in project parameters")
        names.append(project_object["project_name"])

        # Check if names contain bad chars. Underscore is allowed
        spec_chars = re.compile(".*[$&+,:;=?@#|'<>.^*()%!-].*")

        for i in names:
            if(spec_chars.match(i)):
                raise ValueError("Error. No special characters allowed \
including: $&+,:;=?@#|'<>.^*()%!-].* in dataset, project, channel or token \
names")

    def put_data(self, data):
        """
        Try to post data to the server.
        """
        URLPath = self.oo.url("autoIngest/")
        try:
            response = requests.post(URLPath, data=json.dumps(data))
            assert(response.status_code == 200)
            print("From ndio: {}".format(response.content))
        except:
            raise OSError("Error in posting JSON file {}\
".format(response.status_code))

    def post_data(self,
                  file_name=None, legacy=False,
                  verifytype=VERIFY_BY_SLICE):
        """
        Arguments:
            file_name (str): The file name of the json file to post (optional).
                If this is left unspecified it is assumed the data is in the
                AutoIngest object.
            dev (bool): If pushing to a microns dev branch server set this
                to True, if not leave False.
            verifytype (enum): Set http verification type, by checking the
                first slice is accessible or by checking channel folder.
                NOTE: If verification occurs by folder there is NO image size
                or type verification. Enum: [Folder, Slice]

        Returns:
            None
        """
        if (file_name is None):
            complete_example = (
                self.dataset, self.project, self.channels, self.metadata)
            data = json.loads(self.nd_json(*complete_example))

        else:
            try:
                with open(file_name) as data_file:
                    data = json.load(data_file)
            except:
                raise OSError("Error opening file")

        self.verify_path(data, verifytype)
        self.verify_json(data)
        self.put_data(data)

    def output_json(self, file_name='/tmp/ND.json'):
        """
        Arguments:
            file_name(str : '/tmp/ND.json'): The file name to store the json to

        Returns:
            None
        """
        complete_example = (
            self.dataset, self.project, self.channels, self.metadata)
        data = json.loads(self.nd_json(*complete_example))

        self.verify_json(data)
        self.verify_path(data, VERIFY_BY_SLICE)

        f = open(file_name, 'w')
        f.write(str(data))
        f.close()
</code></pre>
  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#ndio.remote.ndingest.NDIngest">NDIngest</a></li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, site_host=None)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>site_host(str)</b>: The site host to post the data to, by default<br />
        http://openconnectome.me.</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.__init__', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.__init__" class="source">
    <pre><code>def __init__(self, site_host=None):
    """
    Arguments:
        site_host(str): The site host to post the data to, by default
            http://openconnectome.me.
    Returns:
        None
    """
    self.channels = {}
    self.dataset = []
    self.project = []
    self.metadata = ''
    if site_host is not None:
        self.oo = nd(site_host)
    else:
        self.oo = nd()
    rd = requests.get('{}/dataset_schema.json'.format(SCHEMA_BASE))
    if (rd.status_code < 300):
        self.DATASET_SCHEMA = load(eval(str(rd.text)))
    else:
        raise OSError("Dataset schema not available")
    rc = requests.get('{}/channel_schema.json'.format(SCHEMA_BASE))
    if (rc.status_code < 300):
        self.CHANNEL_SCHEMA = load(eval(str(rc.text)))
    else:
        raise OSError("Channel schema not available")
    rp = requests.get('{}/project_schema.json'.format(SCHEMA_BASE))
    if (rp.status_code < 300):
        self.PROJECT_SCHEMA = load(eval(str(rp.text)))
    else:
        raise Value("Project schema not available")
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.add_channel">
    <p>def <span class="ident">add_channel</span>(</p><p>self, channel_name, datatype, channel_type, data_url, file_format, file_type, exceptions=None, resolution=None, windowrange=None, readonly=None)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>channel_name (str)</b>: Channel Name is the specific name of a<br />
        specific series of data. Standard naming convention is to do<br />
        ImageTypeIterationNumber or NameSubProjectName.<br />
&emsp;&emsp;&emsp;&emsp;<b>datatype (str)</b>: The data type is the storage method of data in<br />
        the channel. It can be uint8, uint16, uint32, uint64, or<br />
        float32.<br />
&emsp;&emsp;&emsp;&emsp;<b>channel_type (str)</b>: The channel type is the kind of data being<br />
        stored in the channel. It can be image, annotation, or<br />
        timeseries.<br />
&emsp;&emsp;&emsp;&emsp;<b>data_url (str)</b>: This url points to the root directory of the<br />
        files. Dropbox (or any data requiring authentication to<br />
        download such as private s3) is not an acceptable HTTP<br />
        Server. See additional instructions in documentation online<br />
        to format s3 properly so it is http accessible.<br />
&emsp;&emsp;&emsp;&emsp;<b>file_format (str)</b>: File format refers to the overarching kind<br />
        of data, as in slices (normal image data) or catmaid<br />
        (tile-based).<br />
&emsp;&emsp;&emsp;&emsp;<b>file_type (str)</b>: File type refers to the specific type of file<br />
        that the data is stored in, as in, tiff, png, or tif.<br />
&emsp;&emsp;&emsp;&emsp;<b>exceptions (int)</b>: Exceptions is an option to enable the<br />
        possibility for annotations to contradict each other (assign<br />
        different values to the same point). 1 corresponds to True,<br />
        0 corresponds to False.<br />
&emsp;&emsp;&emsp;&emsp;<b>resolution (int)</b>: Resolution is the starting resolution of the<br />
        data being uploaded to the channel.<br />
&emsp;&emsp;&emsp;&emsp;<b>windowrange (int, int)</b>: Window range is the maximum and minimum<br />
        pixel values for a particular image. This is used so that the<br />
        image can be displayed in a readable way for viewing through<br />
        RESTful calls<br />
&emsp;&emsp;&emsp;&emsp;<b>readonly (int)</b>: This option allows the user to control if,<br />
        after the initial data commit, the channel is read-only.<br />
        Generally this is suggested with data that will be publicly<br />
        viewable.</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.add_channel', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.add_channel" class="source">
    <pre><code>def add_channel(self, channel_name, datatype, channel_type,
                data_url, file_format, file_type, exceptions=None,
                resolution=None, windowrange=None, readonly=None):
    """
    Arguments:
        channel_name (str): Channel Name is the specific name of a
            specific series of data. Standard naming convention is to do
            ImageTypeIterationNumber or NameSubProjectName.
        datatype (str): The data type is the storage method of data in
            the channel. It can be uint8, uint16, uint32, uint64, or
            float32.
        channel_type (str): The channel type is the kind of data being
            stored in the channel. It can be image, annotation, or
            timeseries.
        data_url (str): This url points to the root directory of the
            files. Dropbox (or any data requiring authentication to
            download such as private s3) is not an acceptable HTTP
            Server. See additional instructions in documentation online
            to format s3 properly so it is http accessible.
        file_format (str): File format refers to the overarching kind
            of data, as in slices (normal image data) or catmaid
            (tile-based).
        file_type (str): File type refers to the specific type of file
            that the data is stored in, as in, tiff, png, or tif.
        exceptions (int): Exceptions is an option to enable the
            possibility for annotations to contradict each other (assign
            different values to the same point). 1 corresponds to True,
            0 corresponds to False.
        resolution (int): Resolution is the starting resolution of the
            data being uploaded to the channel.
        windowrange (int, int): Window range is the maximum and minimum
            pixel values for a particular image. This is used so that the
            image can be displayed in a readable way for viewing through
            RESTful calls
        readonly (int): This option allows the user to control if,
            after the initial data commit, the channel is read-only.
            Generally this is suggested with data that will be publicly
            viewable.
    Returns:
        None
    """
    self.channels[channel_name] = [
        channel_name.strip().replace(" ", ""), datatype,
        channel_type.lower(), data_url,
        file_format, file_type, exceptions, resolution,
        windowrange, readonly
    ]
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.add_dataset">
    <p>def <span class="ident">add_dataset</span>(</p><p>self, dataset_name, imagesize, voxelres, offset=None, timerange=None, scalinglevels=None, scaling=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Add a new dataset to the ingest.</p>
<h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>dataset_name (str)</b>: Dataset Name is the overarching name of the<br />
        research effort. Standard naming convention is to do<br />
        LabNamePublicationYear or LeadResearcherCurrentYear.<br />
&emsp;&emsp;&emsp;&emsp;<b>imagesize (int, int, int)</b>: Image size is the pixel count<br />
        dimensions of the data. For example is the data is stored<br />
        as a series of 100 slices each 2100x2000 pixel TIFF images,<br />
        the X,Y,Z dimensions are (2100, 2000, 100).<br />
&emsp;&emsp;&emsp;&emsp;<b>voxelres (float, float, float)</b>: Voxel Resolution is the number<br />
        of voxels per unit pixel. We store X,Y,Z voxel resolution<br />
        separately.<br />
&emsp;&emsp;&emsp;&emsp;<b>offset (int, int, int)</b>: If your data is not well aligned and<br />
        there is "excess" image data you do not wish to examine, but<br />
        are present in your images, offset is how you specify where<br />
        your actual image starts. Offset is provided a pixel<br />
        coordinate offset from origin which specifies the "actual"<br />
        origin of the image. The offset is for X,Y,Z dimensions.<br />
&emsp;&emsp;&emsp;&emsp;<b>timerange (int, int)</b>: Time Range is a parameter to support<br />
        storage of Time Series data, so the value of the tuple is a<br />
        0 to X range of how many images over time were taken. It<br />
        takes 2 inputs timeStepStart and timeStepStop.<br />
&emsp;&emsp;&emsp;&emsp;<b>scalinglevels (int)</b>: Scaling levels is the number of levels the<br />
        data is scalable to (how many zoom levels are present in the<br />
        data). The highest resolution of the data is at scaling level<br />
        0, and for each level up the data is down sampled by 2x2<br />
        (per slice). To learn more about the sampling service used,<br />
        visit the the propagation service page.<br />
&emsp;&emsp;&emsp;&emsp;<b>scaling (int)</b>: Scaling is the scaling method of the data being<br />
        stored. 0 corresponds to a Z-slice orientation (as in a<br />
        collection of tiff images in which each tiff is a slice on<br />
        the z plane) where data will be scaled only on the xy plane,<br />
        not the z plane. 1 corresponds to an isotropic orientation<br />
        (in which each tiff is a slice on the y plane) where data<br />
        is scaled along all axis.</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.add_dataset', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.add_dataset" class="source">
    <pre><code>def add_dataset(self, dataset_name, imagesize, voxelres, offset=None,
                timerange=None, scalinglevels=None, scaling=None):
    """
    Add a new dataset to the ingest.
    Arguments:
        dataset_name (str): Dataset Name is the overarching name of the
            research effort. Standard naming convention is to do
            LabNamePublicationYear or LeadResearcherCurrentYear.
        imagesize (int, int, int): Image size is the pixel count
            dimensions of the data. For example is the data is stored
            as a series of 100 slices each 2100x2000 pixel TIFF images,
            the X,Y,Z dimensions are (2100, 2000, 100).
        voxelres (float, float, float): Voxel Resolution is the number
            of voxels per unit pixel. We store X,Y,Z voxel resolution
            separately.
        offset (int, int, int): If your data is not well aligned and
            there is "excess" image data you do not wish to examine, but
            are present in your images, offset is how you specify where
            your actual image starts. Offset is provided a pixel
            coordinate offset from origin which specifies the "actual"
            origin of the image. The offset is for X,Y,Z dimensions.
        timerange (int, int): Time Range is a parameter to support
            storage of Time Series data, so the value of the tuple is a
            0 to X range of how many images over time were taken. It
            takes 2 inputs timeStepStart and timeStepStop.
        scalinglevels (int): Scaling levels is the number of levels the
            data is scalable to (how many zoom levels are present in the
            data). The highest resolution of the data is at scaling level
            0, and for each level up the data is down sampled by 2x2
            (per slice). To learn more about the sampling service used,
            visit the the propagation service page.
        scaling (int): Scaling is the scaling method of the data being
            stored. 0 corresponds to a Z-slice orientation (as in a
            collection of tiff images in which each tiff is a slice on
            the z plane) where data will be scaled only on the xy plane,
            not the z plane. 1 corresponds to an isotropic orientation
            (in which each tiff is a slice on the y plane) where data
            is scaled along all axis.
    Returns:
        None
    """
    self.dataset = (dataset_name.strip().replace(" ", ""), imagesize,
                    voxelres, offset, timerange, scalinglevels, scaling)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.add_metadata">
    <p>def <span class="ident">add_metadata</span>(</p><p>self, metadata=&#39;&#39;)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>metadata(str)</b>: Any metadata as appropriate from the LIMS schema</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.add_metadata', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.add_metadata" class="source">
    <pre><code>def add_metadata(self, metadata=""):
    """
    Arguments:
        metadata(str): Any metadata as appropriate from the LIMS schema
    Returns:
        None
    """
    self.metadata = metadata
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.add_project">
    <p>def <span class="ident">add_project</span>(</p><p>self, project_name, token_name=None, public=None)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>project_name (str)</b>: Project name is the specific project within<br />
        a dataset's name. If there is only one project associated<br />
        with a dataset then standard convention is to name the<br />
        project the same as its associated dataset.<br />
&emsp;&emsp;&emsp;&emsp;<b>token_name (str)</b>: The token name is the default token. If you<br />
        do not wish to specify one, a default one will be created for<br />
        you with the same name as the project name. However, if the<br />
        project is private you must specify a token.<br />
&emsp;&emsp;&emsp;&emsp;<b>public (int)</b>: This option allows users to specify if they want<br />
        the project/channels to be publicly viewable/search-able.<br />
        (1, 0) = (TRUE, FALSE)</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.add_project', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.add_project" class="source">
    <pre><code>def add_project(self, project_name, token_name=None, public=None):
    """
    Arguments:
        project_name (str): Project name is the specific project within
            a dataset's name. If there is only one project associated
            with a dataset then standard convention is to name the
            project the same as its associated dataset.
        token_name (str): The token name is the default token. If you
            do not wish to specify one, a default one will be created for
            you with the same name as the project name. However, if the
            project is private you must specify a token.
        public (int): This option allows users to specify if they want
            the project/channels to be publicly viewable/search-able.
            (1, 0) = (TRUE, FALSE)
    Returns:
        None
    """
    self.project = (project_name.strip().replace(" ", ""),
                    token_name.strip().replace(" ", ""), public)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.channel_dict">
    <p>def <span class="ident">channel_dict</span>(</p><p>self, channel_name, datatype, channel_type, data_url, file_format, file_type, exceptions, resolution, windowrange, readonly)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate the project dictionary.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.channel_dict', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.channel_dict" class="source">
    <pre><code>def channel_dict(self, channel_name, datatype, channel_type, data_url,
                 file_format, file_type, exceptions, resolution,
                 windowrange, readonly):
    """
    Generate the project dictionary.
    """
    channel_dict = {}
    channel_dict['channel_name'] = channel_name
    channel_dict['datatype'] = datatype
    channel_dict['channel_type'] = channel_type
    if exceptions is not None:
        channel_dict['exceptions'] = exceptions
    if resolution is not None:
        channel_dict['resolution'] = resolution
    if windowrange is not None:
        channel_dict['windowrange'] = windowrange
    if readonly is not None:
        channel_dict['readonly'] = readonly
    channel_dict['data_url'] = data_url
    channel_dict['file_format'] = file_format
    channel_dict['file_type'] = file_type
    return channel_dict
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.dataset_dict">
    <p>def <span class="ident">dataset_dict</span>(</p><p>self, dataset_name, imagesize, voxelres, offset, timerange, scalinglevels, scaling)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate the dataset dictionary</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.dataset_dict', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.dataset_dict" class="source">
    <pre><code>def dataset_dict(
    self, dataset_name, imagesize, voxelres,
        offset, timerange, scalinglevels, scaling):
    """Generate the dataset dictionary"""
    dataset_dict = {}
    dataset_dict['dataset_name'] = dataset_name
    dataset_dict['imagesize'] = imagesize
    dataset_dict['voxelres'] = voxelres
    if offset is not None:
        dataset_dict['offset'] = offset
    if timerange is not None:
        dataset_dict['timerange'] = timerange
    if scalinglevels is not None:
        dataset_dict['scalinglevels'] = scalinglevels
    if scaling is not None:
        dataset_dict['scaling'] = scaling
    return dataset_dict
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.identify_imagesize">
    <p>def <span class="ident">identify_imagesize</span>(</p><p>self, image_type, image_path=&#39;/tmp/img.&#39;)</p>
    </div>
    

    
  
    <div class="desc"><p>Identify the image size using the data location and other parameters</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.identify_imagesize', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.identify_imagesize" class="source">
    <pre><code>def identify_imagesize(self, image_type, image_path='/tmp/img.'):
    """
    Identify the image size using the data location and other parameters
    """
    dims = ()
    try:
        if (image_type.lower() == 'png'):
            dims = np.shape(ndpng.load('{}{}'.format(
                image_path, image_type
            )))
        elif (image_type.lower() == 'tif' or image_type.lower() == 'tiff'):
            dims = np.shape(ndtiff.load('{}{}'.format(
                image_path, image_type
            )))
        else:
            raise ValueError("Unsupported image type.")
    except:
        raise OSError('The file was not accessible at {}{}'.format(
            image_path,
            image_type
        ))
    return dims[::-1]
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.nd_json">
    <p>def <span class="ident">nd_json</span>(</p><p>self, dataset, project, channel_list, metadata)</p>
    </div>
    

    
  
    <div class="desc"><p>Genarate ND json object.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.nd_json', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.nd_json" class="source">
    <pre><code>def nd_json(self, dataset, project, channel_list, metadata):
    """
    Genarate ND json object.
    """
    nd_dict = {}
    nd_dict['dataset'] = self.dataset_dict(*dataset)
    nd_dict['project'] = self.project_dict(*project)
    nd_dict['metadata'] = metadata
    nd_dict['channels'] = {}
    for channel_name, value in channel_list.items():
        nd_dict['channels'][channel_name] = self.channel_dict(*value)
    return json.dumps(nd_dict, sort_keys=True, indent=4)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.nd_json_list">
    <p>def <span class="ident">nd_json_list</span>(</p><p>self, dataset, project, channel_list, metadata)</p>
    </div>
    

    
  
    <div class="desc"><p>Genarate ND json object.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.nd_json_list', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.nd_json_list" class="source">
    <pre><code>def nd_json_list(self, dataset, project, channel_list, metadata):
    """
    Genarate ND json object.
    """
    nd_dict = {}
    nd_dict['dataset'] = self.dataset_dict(*dataset)
    nd_dict['project'] = self.project_dict(*project)
    nd_dict['metadata'] = metadata
    nd_dict['channels'] = {}
    for channel_name, value in channel_list.items():
        nd_dict['channels'].append(self.channel_dict(*value))
    return json.dumps(nd_dict, sort_keys=True, indent=4)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.output_json">
    <p>def <span class="ident">output_json</span>(</p><p>self, file_name=&#39;/tmp/ND.json&#39;)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>file_name(str : '/tmp/ND.json')</b>: The file name to store the json to</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.output_json', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.output_json" class="source">
    <pre><code>def output_json(self, file_name='/tmp/ND.json'):
    """
    Arguments:
        file_name(str : '/tmp/ND.json'): The file name to store the json to
    Returns:
        None
    """
    complete_example = (
        self.dataset, self.project, self.channels, self.metadata)
    data = json.loads(self.nd_json(*complete_example))
    self.verify_json(data)
    self.verify_path(data, VERIFY_BY_SLICE)
    f = open(file_name, 'w')
    f.write(str(data))
    f.close()
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.post_data">
    <p>def <span class="ident">post_data</span>(</p><p>self, file_name=None, legacy=False, verifytype=&#39;Slice&#39;)</p>
    </div>
    

    
  
    <div class="desc"><h2 style='font-size:125% !important'>Arguments</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>file_name (str)</b>: The file name of the json file to post (optional).<br />
        If this is left unspecified it is assumed the data is in the<br />
        AutoIngest object.<br />
&emsp;&emsp;&emsp;&emsp;<b>dev (bool)</b>: If pushing to a microns dev branch server set this<br />
        to True, if not leave False.<br />
&emsp;&emsp;&emsp;&emsp;<b>verifytype (enum)</b>: Set http verification type, by checking the<br />
        first slice is accessible or by checking channel folder.<br />
&emsp;&emsp;&emsp;&emsp;<b>NOTE</b>: If verification occurs by folder there is NO image size<br />
&emsp;&emsp;&emsp;&emsp;<b>or type verification. Enum</b>: [Folder, Slice]</p>
<h2 style='font-size:125% !important'>Returns</h2>

<p>&emsp;&emsp;&emsp;&emsp;<b>None</b></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.post_data', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.post_data" class="source">
    <pre><code>def post_data(self,
              file_name=None, legacy=False,
              verifytype=VERIFY_BY_SLICE):
    """
    Arguments:
        file_name (str): The file name of the json file to post (optional).
            If this is left unspecified it is assumed the data is in the
            AutoIngest object.
        dev (bool): If pushing to a microns dev branch server set this
            to True, if not leave False.
        verifytype (enum): Set http verification type, by checking the
            first slice is accessible or by checking channel folder.
            NOTE: If verification occurs by folder there is NO image size
            or type verification. Enum: [Folder, Slice]
    Returns:
        None
    """
    if (file_name is None):
        complete_example = (
            self.dataset, self.project, self.channels, self.metadata)
        data = json.loads(self.nd_json(*complete_example))
    else:
        try:
            with open(file_name) as data_file:
                data = json.load(data_file)
        except:
            raise OSError("Error opening file")
    self.verify_path(data, verifytype)
    self.verify_json(data)
    self.put_data(data)
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.project_dict">
    <p>def <span class="ident">project_dict</span>(</p><p>self, project_name, token_name, public)</p>
    </div>
    

    
  
    <div class="desc"><p>Genarate the project dictionary.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.project_dict', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.project_dict" class="source">
    <pre><code>def project_dict(self, project_name, token_name, public):
    """
    Genarate the project dictionary.
    """
    project_dict = {}
    project_dict['project_name'] = project_name
    if token_name is not None:
        if token_name == '':
            project_dict['token_name'] = project_name
        else:
            project_dict['token_name'] = token_name
    else:
        project_dict['token_name'] = project_name
    if public is not None:
        project_dict['public'] = public
    return project_dict
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.put_data">
    <p>def <span class="ident">put_data</span>(</p><p>self, data)</p>
    </div>
    

    
  
    <div class="desc"><p>Try to post data to the server.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.put_data', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.put_data" class="source">
    <pre><code>def put_data(self, data):
    """
    Try to post data to the server.
    """
    URLPath = self.oo.url("autoIngest/")
    try:
        response = requests.post(URLPath, data=json.dumps(data))
        assert(response.status_code == 200)
        print("From ndio: {}".format(response.content))
    except:
        raise OSError("Error in posting JSON file {}\
rmat(response.status_code))
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.verify_json">
    <p>def <span class="ident">verify_json</span>(</p><p>self, data)</p>
    </div>
    

    
  
    <div class="desc"><p>Verify the JSON against the spec.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.verify_json', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.verify_json" class="source">
    <pre><code>def verify_json(self, data):
    """
    Verify the JSON against the spec.
    """
    names = []
    # Channels
    channel_names = list(data["channels"].copy().keys())
    for i in range(0, len(channel_names)):
        channel_object = data["channels"][channel_names[i]]
        try:
            self.CHANNEL_SCHEMA.validate(channel_object)
        except:
            raise ValueError("channel " + channel_object["channel_name"])
        names.append(channel_object["channel_name"])
    # Dataset"
    dataset_object = data["dataset"]
    try:
        self.DATASET_SCHEMA.validate(dataset_object)
    except:
        raise ValueError("Error in dataset parameters")
    names.append(dataset_object["dataset_name"])
    # Project
    project_object = data["project"]
    try:
        self.PROJECT_SCHEMA.validate(project_object)
    except:
        raise ValueError("Error in project parameters")
    names.append(project_object["project_name"])
    # Check if names contain bad chars. Underscore is allowed
    spec_chars = re.compile(".*[$&+,:;=?@#|'<>.^*()%!-].*")
    for i in names:
        if(spec_chars.match(i)):
            raise ValueError("Error. No special characters allowed \
uding: $&+,:;=?@#|'<>.^*()%!-].* in dataset, project, channel or token \
s")
</code></pre>
  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="ndio.remote.ndingest.NDIngest.verify_path">
    <p>def <span class="ident">verify_path</span>(</p><p>self, data, verifytype)</p>
    </div>
    

    
  
    <div class="desc"><p>Verify the path supplied.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-ndio.remote.ndingest.NDIngest.verify_path', this);">Show source &equiv;</a></p>
  <div id="source-ndio.remote.ndingest.NDIngest.verify_path" class="source">
    <pre><code>def verify_path(self, data, verifytype):
    """
    Verify the path supplied.
    """
    # Insert try and catch blocks
    try:
        token_name = data["project"]["token_name"]
    except:
        token_name = data["project"]["project_name"]
    channel_names = list(data["channels"].copy().keys())
    imgsz = data['dataset']['imagesize']
    for i in range(0, len(channel_names)):
        channel_type = data["channels"][
            channel_names[i]]["channel_type"]
        path = data["channels"][channel_names[i]]["data_url"]
        aws_pattern = re.compile("^(http:\/\/)(.+)(\.s3\.amazonaws\.com)")
        file_type = data["channels"][channel_names[i]]["file_type"]
        if "offset" in data["dataset"]:
            offset = data["dataset"]["offset"][0]
        else:
            offset = 0
        if (aws_pattern.match(path)):
            verifytype = VERIFY_BY_SLICE
        if (channel_type == "timeseries"):
            timerange = data["dataset"]["timerange"]
            try:
                assert(timerange[0] != timerange[1])
            except AssertionError:
                raise ValueError('Timeseries values are the same, did you\
ify the time steps?')
            for j in range(timerange[0], timerange[1] + 1):
                # Test for tifs or such? Currently test for just not
                # empty
                if (verifytype == VERIFY_BY_FOLDER):
                    work_path = "{}/{}/{}/time{}/".format(
                        path, token_name, channel_names[i], ("%04d" % j))
                elif (verifytype == VERIFY_BY_SLICE):
                    work_path = "{}/{}/{}/time{}/{}.{}".format(
                        path, token_name, channel_names[i], ("%04d" % j),
                        ("%04d" % offset), file_type)
                else:
                    raise TypeError('Incorrect verify method')
                # Check for accessibility
                try:
                    if (verifytype == VERIFY_BY_FOLDER):
                        resp = requests.head(work_path)
                        assert(resp.status_code == 200)
                    elif (verifytype == VERIFY_BY_SLICE):
                        resp = requests.get(work_path, stream=True)
                        with open('/tmp/img.{}'.format(file_type),
                                  'wb') as out_file:
                            shutil.copyfileobj(resp.raw, out_file)
                        out_file.close()
                        assert(resp.status_code == 200)
                        resp.close()
                except AssertionError:
                    raise OSError('Files are not http accessible: \
                        Error: {}, Path: {}'.format(resp.status_code,
                                                    work_path))
                # Attempt to Verify imagesize here
                try:
                    if (verifytype == VERIFY_BY_SLICE):
                        assert(list(self.identify_imagesize(file_type)) ==
                               imgsz[0:2])
                except:
                    raise ValueError('File image size does not match\
ided image size.')
        else:
            # Test for tifs or such? Currently test for just not empty
            if (verifytype == VERIFY_BY_FOLDER):
                work_path = "{}/{}/{}/".format(
                    path, token_name, channel_names[i])
            elif (verifytype == VERIFY_BY_SLICE):
                work_path = "{}/{}/{}/{}.{}".format(
                    path, token_name, channel_names[i],
                    ("%04d" % offset), file_type)
            else:
                raise TypeError('Incorrect verify method')
            # Check for accessibility
            if (verifytype == VERIFY_BY_FOLDER):
                resp = requests.head(work_path)
            elif (verifytype == VERIFY_BY_SLICE):
                resp = requests.get(work_path, stream=True)
                with open('/tmp/img.{}'.format(file_type),
                          'wb') as out_file:
                    shutil.copyfileobj(resp.raw, out_file)
                out_file.close()
                resp.close()
            if (resp.status_code >= 300):
                raise OSError('Files are not http accessible: \
                        Error: {}, Path: {}'.format(resp.status_code,
                                                    work_path))
            # Attempt to Verify imagesize here
            try:
                if (verifytype == VERIFY_BY_SLICE):
                    assert(list(self.identify_imagesize(file_type)) ==
                           imgsz[0:2])
            except:
                raise ValueError('File image size does not match\
ided image size.')
</code></pre>
  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="ndio.remote.ndingest.NDIngest.channels" class="name">var <span class="ident">channels</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="ndio.remote.ndingest.NDIngest.dataset" class="name">var <span class="ident">dataset</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="ndio.remote.ndingest.NDIngest.metadata" class="name">var <span class="ident">metadata</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="ndio.remote.ndingest.NDIngest.project" class="name">var <span class="ident">project</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
